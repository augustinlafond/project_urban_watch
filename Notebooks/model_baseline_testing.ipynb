{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e4e6d25",
   "metadata": {},
   "source": [
    "# Notebook - v3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb030d9",
   "metadata": {},
   "source": [
    "Notebook that incorporates Kevin work on preprocessing data and for testing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1930fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774915e0",
   "metadata": {},
   "source": [
    "### Model baseline testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "589d6cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clairedebadts/.pyenv/versions/urban_watch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from urban_watch.ml_logic.data import load_data\n",
    "from urban_watch.ml_logic.package import preprocess_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcc72485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw X shape: (10, 300, 300, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load raw data\n",
    "\n",
    "X_raw, meta = load_data()\n",
    "print(\"Raw X shape:\", X_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede7eb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed X shape: (10, 300, 300, 13)\n"
     ]
    }
   ],
   "source": [
    "#Preprocess images\n",
    "\n",
    "X_processed = np.array([preprocess_image(img) for img in X_raw])\n",
    "print(\"Processed X shape:\", X_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7182c5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten images \n",
    "\n",
    "n_tiles = X_processed.shape[0]\n",
    "flat_dim = np.prod(X_processed.shape[1:])\n",
    "X_flat = X_processed.reshape(n_tiles, flat_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f822e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN before imputer: 5857137\n"
     ]
    }
   ],
   "source": [
    "print(\"NaN before imputer:\", np.isnan(X_flat).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13af59c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacer les Nan du cloud masking\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"constant\", fill_value=0, keep_empty_features=True)\n",
    "X_no_nan = imputer.fit_transform(X_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26eeb442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN after imputer: 0\n",
      "Shape after imputation: (10, 1170000)\n"
     ]
    }
   ],
   "source": [
    "print(\"NaN after imputer:\", np.isnan(X_no_nan).sum())\n",
    "print(\"Shape after imputation:\", X_no_nan.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd250375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: [0 0 0 1 1 0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Generate Fake y for testing with 2 classes (0 - Non Urban and 1 Urban)\n",
    "\n",
    "y_fake = np.random.randint(0, 2, size=len(X_processed))\n",
    "print(\"y:\", y_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b604a2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X: (10, 1170000)\n",
      "Shape y: (10,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape X:\", X_flat.shape)\n",
    "print(\"Shape y:\", y_fake.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56d336d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test/Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X_no_nan, y_fake, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e23faa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression mean accuracy: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Model 1 : Logistic Regression \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "logreg = LogisticRegression(max_iter=500)\n",
    "scores = cross_val_score(logreg, X_no_nan, y_fake, cv=3, scoring=\"accuracy\")\n",
    "\n",
    "print(\"Logistic Regression mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e2f8c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest mean accuracy: 0.49999999999999994\n"
     ]
    }
   ],
   "source": [
    "# Model 2 : RandomForest Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "scores = cross_val_score(rf, X_no_nan, y_fake, cv=3, scoring=\"accuracy\")\n",
    "print(\"Random Forest mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b9aa0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting mean accuracy: 0.49999999999999994\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "scores = cross_val_score(gb, X_no_nan, y_fake, cv=3, scoring=\"accuracy\")\n",
    "print(\"Gradient Boosting mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef996d1e",
   "metadata": {},
   "source": [
    "### Test 2 - Baseline finetuné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e3b3453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_processed: (10, 300, 300, 13)\n",
      "X_tab shape: (10, 55)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b0_mean</th>\n",
       "      <th>b0_std</th>\n",
       "      <th>b0_min</th>\n",
       "      <th>b0_max</th>\n",
       "      <th>b1_mean</th>\n",
       "      <th>b1_std</th>\n",
       "      <th>b1_min</th>\n",
       "      <th>b1_max</th>\n",
       "      <th>b2_mean</th>\n",
       "      <th>b2_std</th>\n",
       "      <th>...</th>\n",
       "      <th>b11_std</th>\n",
       "      <th>b11_min</th>\n",
       "      <th>b11_max</th>\n",
       "      <th>b12_mean</th>\n",
       "      <th>b12_std</th>\n",
       "      <th>b12_min</th>\n",
       "      <th>b12_max</th>\n",
       "      <th>ndvi_strong_pct</th>\n",
       "      <th>ndbi_urban_pct</th>\n",
       "      <th>water_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.042644e-16</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>-3.364899</td>\n",
       "      <td>1.685737</td>\n",
       "      <td>-1.013682e-17</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>-0.501124</td>\n",
       "      <td>13.250412</td>\n",
       "      <td>5.140815e-17</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>-5.864994</td>\n",
       "      <td>3.595883</td>\n",
       "      <td>-9.383798e-16</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>-0.829292</td>\n",
       "      <td>4.290277</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>0.004033</td>\n",
       "      <td>0.001022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.163554e-17</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>-1.362895</td>\n",
       "      <td>8.741292</td>\n",
       "      <td>3.615490e-17</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>-1.053829</td>\n",
       "      <td>20.316168</td>\n",
       "      <td>6.101140e-17</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>-5.377937</td>\n",
       "      <td>5.893429</td>\n",
       "      <td>-5.549778e-15</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>-3.089769</td>\n",
       "      <td>7.081466</td>\n",
       "      <td>0.230189</td>\n",
       "      <td>0.283844</td>\n",
       "      <td>0.245656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7.692338e-17</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>-1.385541</td>\n",
       "      <td>3.848679</td>\n",
       "      <td>3.550310e-17</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>-1.092803</td>\n",
       "      <td>5.832785</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>-5.837613</td>\n",
       "      <td>7.433826</td>\n",
       "      <td>-8.158316e-16</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>-2.924445</td>\n",
       "      <td>5.935637</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.115244</td>\n",
       "      <td>0.112311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.770916e-17</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>-1.806246</td>\n",
       "      <td>3.542543</td>\n",
       "      <td>5.027888e-17</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>-1.569526</td>\n",
       "      <td>5.627428</td>\n",
       "      <td>-1.319821e-16</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>-5.904089</td>\n",
       "      <td>7.019022</td>\n",
       "      <td>5.360986e-15</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>-4.337120</td>\n",
       "      <td>8.352238</td>\n",
       "      <td>0.111978</td>\n",
       "      <td>0.247811</td>\n",
       "      <td>0.225511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.746241e-17</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>-1.862046</td>\n",
       "      <td>4.166743</td>\n",
       "      <td>-7.421524e-17</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>-1.404635</td>\n",
       "      <td>21.401440</td>\n",
       "      <td>-7.858085e-17</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>-4.587105</td>\n",
       "      <td>6.036141</td>\n",
       "      <td>-4.714851e-15</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-1.191020</td>\n",
       "      <td>3.306906</td>\n",
       "      <td>0.265500</td>\n",
       "      <td>0.288467</td>\n",
       "      <td>0.132511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        b0_mean    b0_std    b0_min    b0_max       b1_mean    b1_std  \\\n",
       "0 -1.042644e-16  0.999982 -3.364899  1.685737 -1.013682e-17  0.999986   \n",
       "1  3.163554e-17  0.999974 -1.362895  8.741292  3.615490e-17  0.999979   \n",
       "2 -7.692338e-17  0.999986 -1.385541  3.848679  3.550310e-17  0.999989   \n",
       "3  3.770916e-17  0.999986 -1.806246  3.542543  5.027888e-17  0.999988   \n",
       "4 -1.746241e-17  0.999983 -1.862046  4.166743 -7.421524e-17  0.999970   \n",
       "\n",
       "     b1_min     b1_max       b2_mean    b2_std  ...   b11_std   b11_min  \\\n",
       "0 -0.501124  13.250412  5.140815e-17  0.999989  ...  0.999995 -5.864994   \n",
       "1 -1.053829  20.316168  6.101140e-17  0.999979  ...  0.999994 -5.377937   \n",
       "2 -1.092803   5.832785  0.000000e+00  0.999989  ...  0.999993 -5.837613   \n",
       "3 -1.569526   5.627428 -1.319821e-16  0.999988  ...  0.999994 -5.904089   \n",
       "4 -1.404635  21.401440 -7.858085e-17  0.999973  ...  0.999995 -4.587105   \n",
       "\n",
       "    b11_max      b12_mean   b12_std   b12_min   b12_max  ndvi_strong_pct  \\\n",
       "0  3.595883 -9.383798e-16  0.999997 -0.829292  4.290277         0.001689   \n",
       "1  5.893429 -5.549778e-15  0.999995 -3.089769  7.081466         0.230189   \n",
       "2  7.433826 -8.158316e-16  0.999995 -2.924445  5.935637         0.059900   \n",
       "3  7.019022  5.360986e-15  0.999993 -4.337120  8.352238         0.111978   \n",
       "4  6.036141 -4.714851e-15  0.999998 -1.191020  3.306906         0.265500   \n",
       "\n",
       "   ndbi_urban_pct  water_pct  \n",
       "0        0.004033   0.001022  \n",
       "1        0.283844   0.245656  \n",
       "2        0.115244   0.112311  \n",
       "3        0.247811   0.225511  \n",
       "4        0.288467   0.132511  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from urban_watch.ml_logic.data import load_data\n",
    "from urban_watch.ml_logic.package import preprocess_image, CloudMasker\n",
    "\n",
    "# 1. Charger les données brutes\n",
    "X_raw, meta = load_data()\n",
    "\n",
    "# 2. Preprocessing Kevin → 13 bandes standardisées avec NaN sur nuages\n",
    "X_processed = np.array([preprocess_image(img) for img in X_raw])\n",
    "print(\"X_processed:\", X_processed.shape)  # (n_tiles, H, W, 13)\n",
    "\n",
    "def extract_features(img):\n",
    "    \"\"\"\n",
    "    img : (H, W, 13) après preprocess_image\n",
    "    Retourne un dict de features agrégées pour 1 tuile.\n",
    "    \"\"\"\n",
    "    feats = {}\n",
    "\n",
    "    # Stats simples par bande\n",
    "    for b in range(img.shape[-1]):\n",
    "        band = img[:, :, b]\n",
    "        feats[f\"b{b}_mean\"] = np.nanmean(band)\n",
    "        feats[f\"b{b}_std\"]  = np.nanstd(band)\n",
    "        feats[f\"b{b}_min\"]  = np.nanmin(band)\n",
    "        feats[f\"b{b}_max\"]  = np.nanmax(band)\n",
    "\n",
    "    # On suppose que ndvi, ndbi, mndwi sont les 3 dernières bandes\n",
    "    ndvi  = img[:, :, -3]\n",
    "    ndbi  = img[:, :, -2]\n",
    "    mndwi = img[:, :, -1]\n",
    "\n",
    "    # Pourcentage de pixels forts en végétation / urbain / eau\n",
    "    feats[\"ndvi_strong_pct\"] = np.mean(ndvi > 0.4)\n",
    "    feats[\"ndbi_urban_pct\"]  = np.mean(ndbi > 0.0)\n",
    "    feats[\"water_pct\"]       = np.mean(mndwi > 0.0)\n",
    "\n",
    "    return feats\n",
    "\n",
    "# 3. Appliquer à toutes les tuiles\n",
    "features_list = [extract_features(img) for img in X_processed]\n",
    "X_tab = pd.DataFrame(features_list)\n",
    "\n",
    "print(\"X_tab shape:\", X_tab.shape)\n",
    "X_tab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35bf4730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg accuracy: 0.7777777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y = y_fake  # en attendant le vrai y\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    penalty=\"l2\",\n",
    "    solver=\"lbfgs\"\n",
    ")\n",
    "\n",
    "scores = cross_val_score(logreg, X_tab, y, cv=3, scoring=\"accuracy\")\n",
    "print(\"LogReg accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9699250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest accuracy: 0.49999999999999994\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "scores = cross_val_score(rf, X_tab, y, cv=3, scoring=\"accuracy\")\n",
    "print(\"RandomForest accuracy:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bc97b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoosting accuracy: 0.38888888888888884\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(random_state=42)\n",
    "\n",
    "scores = cross_val_score(hgb, X_tab, y, cv=3, scoring=\"accuracy\")\n",
    "print(\"HistGradientBoosting accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a2b702",
   "metadata": {},
   "source": [
    "### Rafinement des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72923b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import uniform_filter\n",
    "\n",
    "def extract_features_numpy(image_13):\n",
    "    \"\"\"\n",
    "    image_13: (300,300,13)\n",
    "    Retourne un vecteur 1D de features tabulaires\n",
    "    \"\"\"\n",
    "\n",
    "    H, W, C = image_13.shape\n",
    "    feats = []\n",
    "\n",
    "    # ---- 1) Stats globales par bande ----\n",
    "    for c in range(C):\n",
    "        band = image_13[:,:,c]\n",
    "\n",
    "        feats.append(np.nanmean(band))\n",
    "        feats.append(np.nanstd(band))\n",
    "        feats.append(np.nanmin(band))\n",
    "        feats.append(np.nanmax(band))\n",
    "        feats.append(np.nanpercentile(band, 10))\n",
    "        feats.append(np.nanpercentile(band, 90))\n",
    "\n",
    "    # ---- 2) Texture simple : variance locale ----\n",
    "    for c in range(C):\n",
    "        band = image_13[:,:,c]\n",
    "        mean_3 = uniform_filter(band, size=3)\n",
    "        mean_sq_3 = uniform_filter(band**2, size=3)\n",
    "        local_var = mean_sq_3 - mean_3**2\n",
    "\n",
    "        feats.append(np.nanmean(local_var))\n",
    "        feats.append(np.nanmax(local_var))\n",
    "\n",
    "    # ---- 3) Global NDVI / NDBI / MNDWI stats ----\n",
    "    NDVI = image_13[:,:,10]   # si indices ajoutés en 11,12,13\n",
    "    NDBI = image_13[:,:,11]\n",
    "    MNDWI = image_13[:,:,12]\n",
    "\n",
    "    for ind in [NDVI, NDBI, MNDWI]:\n",
    "        feats.append(np.nanmean(ind))\n",
    "        feats.append(np.nanstd(ind))\n",
    "        feats.append(np.nanmean(ind > 0))  # fraction positive\n",
    "\n",
    "    return np.array(feats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urban_watch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
